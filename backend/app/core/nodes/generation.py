from langchain_core.output_parsers import StrOutputParser
from typing import Dict, Any

from app.core.state import AgentState
from app.services.llm_factory import llm_factory
from app.prompts.generation import rag_generation_prompt
from app.core.logger import logger

# åˆå§‹åŒ–ç”Ÿæˆé“¾
llm = llm_factory.get_llm(mode="smart")
chain = rag_generation_prompt | llm | StrOutputParser()

async def generation_node(state: AgentState) -> Dict[str, Any]:
    logger.info("ğŸ§  [GENERATION] ç”Ÿæˆä¸­...")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ ¡éªŒå¤±è´¥çš„åé¦ˆ
    feedback = ""
    if state.get("validation_reason") and state.get("retry_count", 0) > 0:
        feedback = f"\n\nâš ï¸ ä¸Šä¸€æ¬¡ç”Ÿæˆçš„å›ç­”æœªé€šè¿‡æ ¡éªŒï¼ŒåŸå› æ˜¯ï¼š{state['validation_reason']}ã€‚è¯·æ ¹æ®æ­¤åé¦ˆæ”¹è¿›å›ç­”ã€‚"
        logger.warning(f"   - æ¥æ”¶åˆ°é‡è¯•åé¦ˆ: {state['validation_reason']}")

    current_context = state.get("rag_context", "") + feedback

    try:
        response = await chain.ainvoke({
            "context": current_context, # ä¼ å…¥å¸¦åé¦ˆçš„ä¸Šä¸‹æ–‡
            "messages": state.get("messages", []),
            "question": state["query"]
        })
        return {"answer": response}
    except Exception as e:
        return {"answer": "ç”Ÿæˆå‡ºé”™"}