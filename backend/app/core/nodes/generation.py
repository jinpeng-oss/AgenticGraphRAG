from langchain_core.output_parsers import StrOutputParser
from typing import Dict, Any

from app.core.state import AgentState
from app.services.llm_factory import llm_factory
from app.prompts.generation import rag_generation_prompt
from app.core.logger import logger

# åˆå§‹åŒ–ç”Ÿæˆé“¾
llm = llm_factory.get_llm(mode="smart")
chain = rag_generation_prompt | llm | StrOutputParser()

async def generation_node(state: AgentState) -> Dict[str, Any]:
    """
    ğŸ§  ç”ŸæˆèŠ‚ç‚¹
    æ³¨æ„ï¼šè¿™é‡Œåªç”Ÿæˆå†…å®¹ï¼Œä¸æ›´æ–° messages å†å²ï¼Œå†å²æ›´æ–°ç•™ç»™ Validation èŠ‚ç‚¹ã€‚
    """
    logger.info("ğŸ§  [GENERATION] æ­£åœ¨ç”Ÿæˆå›ç­”...")
    
    try:
        response = await chain.ainvoke({
            "context": state.get("rag_context", ""),
            "messages": state.get("messages", []),
            "question": state["query"]
        })
        
        logger.info(f"åˆæ­¥ç”Ÿæˆå›ç­”: {response[:50]}...")
        
        return {"answer": response}
        
    except Exception as e:
        logger.error(f"âŒ [GENERATION] å¤±è´¥: {e}")
        return {"answer": "æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ã€‚"}