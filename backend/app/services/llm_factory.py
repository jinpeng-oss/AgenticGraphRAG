# app/services/llm_factory.py
from typing import Literal
from langchain_openai import ChatOpenAI
from langchain_core.language_models import BaseChatModel
from app.core.config import settings
from app.core.logger import logger

class LLMFactory:
    """
    LLM å·¥å‚ç±»
    ç”¨äºæ ¹æ®ä¸åŒçš„ä»»åŠ¡éœ€æ±‚ï¼ˆæ¨¡å¼ï¼‰ï¼Œç”Ÿäº§é…ç½®ä¸åŒçš„ LangChain ChatModel å®ä¾‹
    æ”¯æŒ create_agent é«˜å±‚ API å’Œä½å±‚ ChatOpenAI ä½¿ç”¨
    """
    
    @staticmethod
    def get_llm(
        mode: Literal["smart", "fast", "strict"] = "smart"
    ) -> BaseChatModel:
        """
        è·å– LLM å®ä¾‹çš„æ ¸å¿ƒæ–¹æ³•
        
        Args:
            mode:
                - "smart": é«˜æ™ºèƒ½æ¨¡å¼ (qwen-max), é€‚åˆç”Ÿæˆå›ç­”ã€æ¨ç†ã€create_agent
                - "fast":  æé€Ÿæ¨¡å¼ (qwen-plus), é€‚åˆå®ä½“æŠ½å–ã€ç®€å•åˆ†ç±»
                - "strict": ä¸¥è°¨æ¨¡å¼ (qwen-plus, Temp=0), é€‚åˆ Validator æ ¡éªŒã€JSON æ ¼å¼åŒ–
        
        Returns:
            BaseChatModel å®ä¾‹ (å¯ç›´æ¥ç”¨äº create_agent çš„ model å‚æ•°)
            
        Examples:
            >>> # ç›´æ¥ç”¨
            >>> llm = LLMFactory.get_llm(mode="fast")
            >>> response = llm.invoke([{"role": "user", "content": "..."}])
            
            >>> # ç”¨äº create_agent
            >>> agent = create_agent(model=llm, tools=[...])
        """
        
        # 1. API Key æ£€æŸ¥
        if not settings.LLM_API_KEY:
            logger.error("âŒ æœªæ‰¾åˆ° LLM_API_KEYï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡æˆ– .env é…ç½®")
            raise ValueError("LLM_API_KEY is missing")

        try:
            # 2. æ ¹æ®æ¨¡å¼é…ç½®å‚æ•°
            config_map = {
                "smart": {
                    "model": getattr(settings, "MODEL_SMART", "qwen-max"),
                    "temperature": 0.7,
                    "max_tokens": 20000
                },
                "fast": {
                    "model": getattr(settings, "MODEL_FAST", "qwen-plus"),
                    "temperature": 0.0,
                    "max_tokens": 20000
                },
                "strict": {
                    "model": getattr(settings, "MODEL_STRICT", "qwen-plus"),
                    "temperature": 0.0,
                    "max_tokens": 20000
                }
            }

            if mode not in config_map:
                error_msg = f"âŒ æœªçŸ¥çš„ LLM æ¨¡å¼: {mode}ï¼Œæ”¯æŒ: smart/fast/strict"
                logger.error(error_msg)
                raise ValueError(error_msg)

            # 3. åˆ›å»º LLM å®ä¾‹
            config = config_map[mode]
            llm = ChatOpenAI(
                base_url=settings.LLM_BASE_URL,
                api_key=settings.LLM_API_KEY,
                model=config["model"],
                temperature=config["temperature"],
                max_tokens=config["max_tokens"]
            )

            logger.success(
                f"âœ… LLM å·²åˆå§‹åŒ– | Mode: {mode} | Model: {config['model']} | Temp: {config['temperature']}"
            )
            return llm

        except Exception as e:
            logger.error(f"âŒ LLM åˆå§‹åŒ–å¤±è´¥ (Mode: {mode}): {str(e)}")
            raise
        
llm_factory = LLMFactory()

if __name__ == "__main__":
    from langchain_core.messages import HumanMessage
    from langchain.agents import create_agent
    from langchain.tools import tool

    logger.info("ğŸ¤– å¼€å§‹æµ‹è¯• LLM Factory...")

    try:
        # 1. æµ‹è¯• Fast æ¨¡å¼
        logger.info("1ï¸âƒ£ æµ‹è¯• FAST æ¨¡å¼...")
        fast_llm = LLMFactory.get_llm(mode="fast")
        res_fast = fast_llm.invoke([HumanMessage(content="1+1ç­‰äºå‡ ï¼Ÿåªå›ç­”æ•°å­—ã€‚")])
        logger.success(f"âœ… Fast Mode å“åº”: {res_fast.content.split()[0]}")

        # 2. æµ‹è¯• Smart æ¨¡å¼
        logger.info("2ï¸âƒ£ æµ‹è¯• SMART æ¨¡å¼...")
        smart_llm = LLMFactory.get_llm(mode="smart")
        if smart_llm:
            logger.success("âœ… Smart Mode åˆå§‹åŒ–æˆåŠŸ")

        # 3. æµ‹è¯• Strict æ¨¡å¼
        logger.info("3ï¸âƒ£ æµ‹è¯• STRICT æ¨¡å¼...")
        strict_llm = LLMFactory.get_llm(mode="strict")
        if strict_llm:
            logger.success("âœ… Strict Mode åˆå§‹åŒ–æˆåŠŸ")

        # 4. æµ‹è¯•ä¸ create_agent é›†æˆ
        logger.info("4ï¸âƒ£ æµ‹è¯•ä¸ create_agent é›†æˆ...")
        
        @tool
        def demo_tool(query: str) -> str:
            """æ¼”ç¤ºå·¥å…·"""
            return f"Demo result for: {query}"
        
        agent = create_agent(
            model=LLMFactory.get_llm(mode="smart"),
            tools=[demo_tool],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"
        )
        logger.success("âœ… Agent åˆ›å»ºæˆåŠŸ")

        logger.success("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")