import asyncio
from typing import List, Dict, Any
from pydantic import BaseModel, Field
from langchain_qdrant import QdrantVectorStore
from qdrant_client import models
from langchain_core.output_parsers import PydanticOutputParser

from app.services.embedding_factory import embedding_factory
from app.services.llm_factory import llm_factory
from app.services.neo4j_service import neo4j_manager
from app.services.qdrant_service import qdrant_manager
from app.prompts.extraction import entity_extraction_prompt
from app.core.logger import logger
from app.core.config import settings

# --- æ•°æ®ç»“æ„å®šä¹‰ ---
class ExtractionFormat(BaseModel):
    entities: Any = Field(..., description="å®ä½“åˆ—è¡¨")
    
    @property
    def flat_entities(self) -> List[str]:
        """ğŸ¦¾ æ™ºèƒ½é€‚é…æ‰€æœ‰å¯èƒ½çš„ DeepSeek è¾“å‡ºæ ¼å¼"""
        entities_raw = self.entities
        
        # æƒ…å†µ1ï¼šç›´æ¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
        if isinstance(entities_raw, list) and all(isinstance(e, str) for e in entities_raw):
            return [e.strip() for e in entities_raw if e.strip()]
        
        # æƒ…å†µ2ï¼šå®ä½“å¯¹è±¡æ•°ç»„ [{"name": "...", "type": "..."}]
        elif isinstance(entities_raw, list):
            all_names = []
            for item in entities_raw:
                if isinstance(item, dict):
                    all_names.append(item.get("name", "") or item.get("entity", ""))
                elif isinstance(item, str):
                    all_names.append(item)
            return [e.strip() for e in all_names if e.strip()]
        
        # æƒ…å†µ3ï¼šåˆ†ç±»å­—å…¸ {"person": [...], "company": [...]}
        elif isinstance(entities_raw, dict):
            all_entities = []
            for category, items in entities_raw.items():
                if isinstance(items, list):
                    for item in items:
                        if isinstance(item, str):
                            all_entities.append(item)
                        elif isinstance(item, dict):
                            all_entities.append(item.get("name", "") or item.get("entity", ""))
            return [e.strip() for e in all_entities if e.strip()]
        
        return []

class HybridSearchService:
    def __init__(self):
        self.embeddings = embedding_factory.get_embedding()
        self.qdrant_vectorstore = None
        self.neo4j_driver = neo4j_manager
        
        # 1. åˆå§‹åŒ– Qdrant
        self._init_qdrant()
        
        # 2. åˆå§‹åŒ–æå–å™¨ components
        # æˆ‘ä»¬æŠŠ Parser å­˜ä¸ºæˆå‘˜å˜é‡ï¼Œä»¥ä¾¿åç»­è·å– instructions
        self.extraction_parser = PydanticOutputParser(pydantic_object=ExtractionFormat)
        self.extraction_chain = self._init_extraction()
        
        logger.success("âœ… HybridSearchåˆå§‹åŒ–å®Œæˆ")

    def _init_qdrant(self):
        """Qdrantå®ä½“åº“åˆå§‹åŒ–ï¼ˆå¸¦è‡ªåŠ¨å»ºè¡¨åŠŸèƒ½ï¼‰"""
        client = qdrant_manager.get_client()
        collection_name = settings.COLLECTION_NAME
        
        if not client.collection_exists(collection_name):
            try:
                dummy_vec = self.embeddings.embed_query("test")
                vector_size = len(dummy_vec)
                client.create_collection(
                    collection_name=collection_name,
                    vectors_config=models.VectorParams(
                        size=vector_size,
                        distance=models.Distance.COSINE
                    )
                )
                logger.success(f"âœ… å·²åˆ›å»ºæ–°é›†åˆ: {collection_name}")
            except Exception as e:
                logger.error(f"âŒ Qdrant å»ºè¡¨å¤±è´¥: {e}")

        self.qdrant_vectorstore = QdrantVectorStore(
            client=client,
            collection_name=collection_name,
            embedding=self.embeddings
        )

    def _init_extraction(self):
        """åˆå§‹åŒ–æå–é“¾ï¼šPrompt | LLM | Parser"""
        llm = llm_factory.get_llm(mode="fast")
        # æ„é€  LCEL Chain
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨äº†ä¹‹å‰ä¿å­˜çš„ self.extraction_parser
        chain = entity_extraction_prompt | llm | self.extraction_parser
        return chain

    async def search(self, query: str, top_k: int = 5) -> Dict[str, Any]:
        # Step 1: LLMæŠ½å®ä½“
        entities = await self._extract_entities(query)
        
        if not entities:
            logger.info("æœªæå–åˆ°å®ä½“ï¼Œfallback åˆ°çº¯å‘é‡æ£€ç´¢")
            return {
                "context_text": "",
                "entities": [],
                "matched_entities": [],
                "graph_context": "æ— å®ä½“"
            }
        
        # Step 2: Qdrantæ‰¾ç›¸ä¼¼å®ä½“
        matched_entities = await self._qdrant_match_entities(entities, top_k)
        
        logger.info(f"ğŸ” [RETRIEVAL]: åŒ¹é…åˆ°å®ä½“: {matched_entities}")
        
        # Step 3: Neo4jæŸ¥å›¾ä¿¡æ¯
        graph_context = await self._neo4j_get_graph(matched_entities)

        logger.info(f"ğŸ” [RETRIEVAL]: æŸ¥æ‰¾åˆ°å›¾è°±å…³ç³»: {graph_context}")

        # ç»„è£…ä¸Šä¸‹æ–‡
        context_parts = []
        if matched_entities:
            names = [e['name'] for e in matched_entities[:3]]
            context_parts.append(f"æ¶‰åŠå®ä½“ï¼š{', '.join(names)}")
        if graph_context:
            context_parts.append(f"çŸ¥è¯†å›¾è°±å…³ç³»ï¼š\n{graph_context}")
        return {
            "context_text": "\n".join(context_parts),
            "entities": entities,
            "matched_entities": matched_entities,
            "graph_context": graph_context
        }

    async def _extract_entities(self, query: str) -> List[str]:
        """LLMå®ä½“æå–"""
        try:
            # ğŸ”´ æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨ .ainvoke() è€Œä¸æ˜¯ç›´æ¥è°ƒç”¨ ()
            result: ExtractionFormat = await self.extraction_chain.ainvoke({
                "query": query,
                "text": query, # è¿™é‡Œå‡è®¾ text å°±æ˜¯ query æœ¬èº«
                "format_instructions": self.extraction_parser.get_format_instructions()
            })
            
            entities = result.flat_entities
            logger.info(f"æå–å®ä½“: {entities}")
            return entities
        except Exception as e:
            logger.warning(f"å®ä½“æå–å¤±è´¥: {e}")
            return []

    async def _qdrant_match_entities(self, entities: List[str], top_k: int) -> List[Dict]:
        if not self.qdrant_vectorstore or not entities:
            return []

        tasks = []
        for entity in entities[:3]:
            # å¹¶å‘æŸ¥è¯¢
            tasks.append(self.qdrant_vectorstore.asimilarity_search_with_score(entity, k=2))
        
        results_groups = await asyncio.gather(*tasks, return_exceptions=True)
        
        all_results = []
        for i, group in enumerate(results_groups):
            if isinstance(group, Exception):
                continue
            
            origin_query = entities[i]
            for doc, score in group:
                payload = doc.metadata
                all_results.append({
                    "name": payload.get("name", origin_query),
                    "score": float(score),
                    "type": payload.get("type", "unknown")
                })

        unique_results = {}
        for r in all_results:
            name = r["name"]
            if name not in unique_results or r["score"] > unique_results[name]["score"]:
                unique_results[name] = r
        
        return sorted(unique_results.values(), key=lambda x: x["score"], reverse=True)[:top_k]

    async def _neo4j_get_graph(self, matched_entities: List[Dict]) -> str:
        if not self.neo4j_driver or not matched_entities:
            return ""
            
        entity_names = [e["name"] for e in matched_entities[:3]]
        
        cypher = """
        MATCH (s:Entity)-[r]-(t:Entity)
        WHERE s.name IN $names
        RETURN s.name as source, type(r) as rel, t.name as target
        LIMIT 15
        """
        
        try:
            records = self.neo4j_driver.execute_query(cypher, {"names": entity_names})
            data = getattr(records, 'records', records)
            if not data: return "æ— ç›´æ¥å…³è”ä¿¡æ¯"

            relations = []
            for record in data:
                src = record.get('source') if isinstance(record, dict) else record['source']
                rel = record.get('rel') if isinstance(record, dict) else record['rel']
                tgt = record.get('target') if isinstance(record, dict) else record['target']
                relations.append(f"{src} -[{rel}]-> {tgt}")
            
            return "\n".join(relations)
        except Exception as e:
            logger.warning(f"Neo4jæŸ¥è¯¢å¤±è´¥: {e}")
            return ""

hybrid_search_service = None

def init_hybrid_search():
    """
    åœ¨ FastAPI å¯åŠ¨æ—¶è°ƒç”¨æ­¤å‡½æ•°è¿›è¡Œåˆå§‹åŒ–
    """
    global hybrid_search_service
    try:
        hybrid_search_service = HybridSearchService()
        logger.success("ğŸš€ HybridSearchService å…¨å±€å®ä¾‹å·²åˆ›å»º")
    except Exception as e:
        logger.error(f"âŒ HybridSearchService åˆå§‹åŒ–å¤±è´¥: {e}")


if __name__ == "__main__":
    async def test():
        if hybrid_search_service:
            tests = [
                "é©¬æ–¯å…‹çš„å¤ªç©ºå…¬å¸æ˜¯ä»€ä¹ˆ",
                "SpaceXå’Œæ˜Ÿèˆ°çš„å…³ç³»", 
                "ç‰¹æ–¯æ‹‰åœ¨ä¸­å›½å»ºå‚äº†å—"
            ]
            for query in tests:
                print(f"\n{'='*60}")
                print(f"ğŸ” {query}")
                result = await hybrid_search_service.search(query)
                logger.info(f"ç®€è¦ä¸Šä¸‹æ–‡: {result['context_text']}")
                logger.info(f"æŠ½å–å®ä½“: {result['entities']}")
                logger.info(f"åŒ¹é…å®ä½“: {result['matched_entities']}")
                logger.info(f"å›¾è°±: {result['graph_context']}")
    
    asyncio.run(test())